---
title: 'TV Show and Movie Popularity Project'
theme:
  dark: darkly
format:
  html:
    toc: true
    code-fold: true
editor: visual
jupyter: python3
---

::: panel-tabset
#### Home

**Abstract**

In this data science project, we will analyze a dataset containing information about titles on different streaming services and build a model to predict the popularity of an arbitrary title. The datasets used were sourced from [Kaggle](https://www.kaggle.com/) and the specific links can be found on the `Data Preprocessing` tab above. These provide valuable insights into the popularity and characteristics of different titles available on the streaming platforms and will help us in predicting the outcomes of future titles.

**Problem Statement**

The streaming services industry has seen rapid growth in recent years and has undoubtedly revolutionized the way we consume content. With numerous platforms offering a vast array of media types, it has become increasingly important for creators and streaming platforms to understand what makes a certain movie or TV show popular. This project aims to explore the Kaggle dataset and uncover the key factors that contribute to their popularity through fitting a series of different models.

**Data Description**

The dataset contains several variables that provide valuable information for our analysis. Here is a brief description of the main variables:

-   **`type`**: Indicates whether the show is a TV series or a movie.
-   **`title`**: The title of the TV show.
-   **`director`**: The name of the director(s) of the show.
-   **`cast`**: The names of the main cast members.
-   **`country`**: The countries the show was released in.
-   **`release_year`**: The year when the show was released.
-   **`rating`**: The content rating assigned to the show (TV-14, PG-13, etc.).
-   **`duration`**: The number of seasons (for TV series) or the duration (minutes) of the movie (for movies).
-   **`listed_in`**: The genre(s) or category(s) the show belongs to.
-   **`description`**: A brief summary or description of the show.
-   **`score`**: Rating of the show or movie - scraped from [IMDb.](https://www.imdb.com/)
-   **`director_score`**: Calculated score based on the directors of the title.

Together, these variables provide a set of features that allow us to analyze and understand the characteristics that determine the popularity of TV shows. By exploring these variables and their relationships, we can gain insights into the factors that contribute to a show's popularity, like the impact of different genres or countries of origin, and begin to create better shows that more people would watch.

#### Data Preprocessing

**Source**

We combined the below four datasets found on Kaggle to get a comprehensive dataset of movies and TV shows available on the major streaming platforms.

-   [Disney+](https://www.kaggle.com/datasets/shivamb/disney-movies-and-tv-shows)
-   [Hulu](https://www.kaggle.com/datasets/shivamb/hulu-movies-and-tv-shows)
-   [Amazon Prime](https://www.kaggle.com/datasets/shivamb/amazon-prime-movies-and-tv-shows)
-   [Netflix](https://www.kaggle.com/datasets/shivamb/netflix-shows)

**Cleaning** 

Need to add in here how you cleaned the data and how we address nulls. 
Need to also mention how we handeled the countries (listed_in column) as well as the list of genres
Directors were cleaned?

**Train Split** 

talk to colton

#### Exploratory Data Analysis (EDA)

In this section we will explore and visualize our dataset to gain a better understanding of what we are working with, identify any obvious patterns, correlations, or trends.

```{python}
import pandas as pd
data = pd.read_csv("../Data/data/streaming_titles_final.csv")
```

```{python}
import matplotlib.pyplot as plt

data = data
data.head()
```

```{python}
print("We have " + str(len(data)) + " total different movies and TV shows that we are working with.")
```

```{python}
data.isna().sum()
```
We can verify that there are no missing values, as these were handled during the data cleaning step.

```{python}
print(data.shape)
print("There are a total of 89 columns that were are working with.")
```


```{python}
import seaborn as sns

sns.countplot(x=data["type"])

# Add labels and title
plt.xlabel("Type")
plt.ylabel("Count")
plt.title("Distribution of Titles by Type")

# Display the plot
plt.show()
```

```{python}
# | fig.width: 10
# 1. Line Chart of the Number of Titles Released per Year

# Group data by year and count number of titles
counts = data.groupby("release_year")["title"].count()

# Create line chart
#plt.figure(figsize=(10,10))
plt.plot(counts.index, counts.values)

# Add labels and title
plt.xlabel("Year")
plt.ylabel("Number of Titles Released")
plt.title("Number of Titles Released per Year")

# Display chart
plt.show()
```

```{python}
# | fig.width: 10

# 2. Histogram of the Distribution of Content Ratings

# Create histogram of content ratings
#plt.figure(figsize=(20,10))
plt.hist(data["rating"].dropna(), bins=10)

# Add labels and title
plt.xlabel("Content Rating")
plt.xticks(rotation=45)
plt.ylabel("Frequency")
plt.title("Distribution of Content Ratings")

# Display chart
plt.show()
```

```{python}
# | fig.width: 10

# 3. Bar Chart of the Number of Titles per Country (count > 10)

# Extract first country from country column
chart = data.copy()
chart["country"] = chart["country"].str.split(", ").str[0]

# Group data by country and count number of titles
counts = chart.groupby("country")["title"].count()
counts = counts[counts > 10].sort_values(ascending=False)

# Create bar chart
#plt.figure(figsize=(20,10))
plt.bar(counts.index, counts.values)

# Add labels and title
plt.xlabel("Country")
plt.xticks(rotation=90)
plt.ylabel("Number of Titles")
plt.title("Number of Titles per Country")

# Display chart
plt.show()
```

```{python}
# | fig.width: 10

# 4. Movie and Rating Scatter Plot

# Filter out TV shows and missing ratings
movies = data[(data["type"] == "Movie") & (data["score"].notnull())]

# Create scatter plot of IMDb rating vs. runtime
#plt.figure(figsize=(20,10))
plt.scatter(movies["score"], movies["duration"], alpha=0.5)

# Add labels and title
plt.xlabel("IMDb Rating")
plt.ylabel("Runtime (minutes)")
plt.title("IMDb Rating vs. Runtime for Movies")

# Display chart
plt.show()
```

```{python}
# | fig.width: 10

# 5. TV Show and Rating Scatter Plot

# Filter out Movies and missing ratings
tv = data[(data["type"] == "TV Show") & (data["score"].notnull())]

# Create scatter plot of IMDb rating vs. runtime
#plt.figure(figsize=(20,10))
plt.scatter(tv["score"], tv["duration"], alpha=0.5)

# Add labels and title
plt.xlabel("IMDb Rating")
plt.ylabel("Runtime (seasons)")
plt.title("IMDb Rating vs. Runtime for TV Shows")

# Display chart
plt.show()
```

```{python}
# | fig.width: 10

# 6. Top 15 Genres By Number of Titles

# Get list of genre columns
genre_cols = [col for col in data.columns if col.startswith("genre")]

# Sum the number of true values in each genre column to get the total number of titles for each genre
genre_counts = data[genre_cols].sum()#.sort_values(ascending=False)

# Get the top 10 genres by number of titles
top_genres = genre_counts[:15]

# Remove "genre." from the genre names in the x-axis labels
labels = [col.replace("genre.", "") for col in top_genres.index]

# Create bar chart
# plt.figure(figsize=(20, 10))
plt.bar(labels, top_genres.values, color='purple')

# Add labels and title
plt.xlabel("Genre")
plt.xticks(rotation=45, ha='right')
plt.ylabel("Number of Titles")
plt.title("Top 10 Genres by Number of Titles")

# Display chart
plt.show()
```

Overall, this section uncovered several intriguing patterns. We almost have an 80/20 split of movies and shows within our data. The number of released titles per year is exponential, and is only hindered in 2020, due to the COVID-19 pandemic limiting production. The few bar plots also demonstrate the ratings, major countries, and the types of media within the dataset. Now we have a much better picture of the data that we are working with and can keep this in mind for our future models.

#### Methods

In this section, we describe the machine learning models employed for predicting the popularity score of TV shows and movies in our project. We utilized several models, including beta regression, decision tree, K-Nearest Neighbors (KNN), and random forest. Each of these models offers unique characteristics and can capture different aspects of the data to make accurate predictions.

*Train-Test Split*

To evaluate the performance of our machine learning models, we employed a train-test split approach. This process involves dividing our dataset, consisting of TV shows and movies, into two separate subsets: a training set and a testing set. The training set, which constitutes a majority of the data, was used to train our models to learn the underlying patterns and relationships between the features and the target variable, which in our case is the popularity score. The testing set, on the other hand, served as an unseen dataset to assess the models' generalization ability and determine their predictive performance on new, unseen instances. By randomly assigning the data points to the training and testing sets, we ensured that the evaluation process is unbiased and representative of real-world scenarios. After fitting each model with the training set, we are left with the root mean squared error (rMSE) value. 

This metric gives us the weighted distance our model is from the correct metric. For example, if we had a rMSE of 21.7, this means that if we guessed the mean every time, we would be, on average, off by 21.7 points. So, our model should try to get a better rMSE than 21.7, or minimize this value. 

**Methods Used**


*Beta Regression*

Beta regression is a statistical model specifically designed for modeling continuous variables bounded between 0 and 1. In our case, we used beta regression to predict the popularity score, which ranges from 0 to 100. Beta regression takes into account the distributional characteristics of the data and can handle the inherent boundedness of the popularity score, allowing for accurate predictions.

*Decision Tree*

Decision trees are intuitive models that create a flowchart-like structure of decisions and their potential consequences. Each internal node represents a decision based on a specific feature, and each leaf node represents the predicted outcome (popularity score). Decision trees are capable of handling both numerical and categorical features, and they offer interpretability by visualizing the decision-making process.

*Random Forest*

Random forest is model that combines multiple decision trees to make predictions. It averages across the individual tree predictions. Random forest can handle non-linear relationships, capture feature interactions, and effectively handle high-dimensional data. It provides robust predictions and reduces the risk of overfitting compared to individual decision trees.

*K-Nearest Neighbors (KNN)*

K-Nearest Neighbors is a non-parametric algorithm that makes predictions based on the similarity of a given data point to its k nearest neighbors in the feature space. In our case, KNN is used to predict the popularity score by finding the k most similar instances in the training data. KNN is particularly suitable when similar shows or movies tend to have similar scores.

*Additional Information*

For all of these models, we defined the set of predictor variables to be the same. These predictors included genre information, duration, release year, type, rating, director's average score, cast's average score, and country. 

Also, to evaluate all four model's performance and validate its predictive ability, we employed a cross-validation strategy. Code was written so that the dataset was divided into five subsets or folds, with each fold serving as a testing set while the remaining four folds were used for training. The grid search was performed within this cross-validation framework, optimizing the model's hyperparameters based on the negative root mean squared error (RMSE) metric. By utilizing cross-validation, we obtained robust estimates of the model's performance and ensured the generalization of the results to unseen data.


#### Results

Here we need to explain the code in fitting each of the models, such as the variables used, the number of folds, cross validation, etc.

*Beta Regression*

*Decision Tree*

*Random Forest*

*K-Nearest Neighbors (KNN)*

#### App

<iframe src="https://tv-popularity-model.streamlit.app//?embed=true" height="750" style="width:100%;border:none;">

</iframe>

#### Discussion and Interpretation

Discussion and Interpretation Page
:::
